# Pandas

- Series: 1차원, 리스트를 인자로 받음 pd.Series([~~])
- DataFrame: 2차원 행렬, 딕셔너리 형태에 value는 리스트 형태로 입력받음
  - value에 단일값 입력 시 해당 컬럼의 컬럼값이 전부 그 단일값이 됨.
- 저장시 df.to_csv('파일명.csv',[인덱스][인코딩])
- 로드 시 df = pd.read_csv('파일명.csv')

# Datetime

- Datetime형 인덱스를 가진 df의 메소드 resample.
  - dir(df)로 찾을 수 있음.
  - df.resample('W').sum() -> 이러면 요일별 합계를 구함.

```python
df_w = df.resample('W').sum()
df_w

df_max=df_w.Sales.max()
df_min=df_w.Sales.min()

abs(df_max-df_min)

- 이 예제 기억 꼭 해놓자.. 주 별로 Sales합계를 구해서 최댓값 최솟값 차이 구하는..
```

# DateOffset

- 뭔가 datetime형 값에 연, 월 등 더하기 좋음
- df.날짜 + pd.DateOffset(year=100) 하면, 윤년 등을 알아서 계산해서 100년을 더해줌.

# 컬럼.shift()

- 시차를 만드는 거라 한다..
- df['pre_pv']=pv.shift(1) 하면, pv컬럼의 이전 행의 값을 가져와 pre_pv 값을 채우는 거다.
- 100, 200, 300 이면, pre_pv는 NaN, 100, 200..

# 일원배치 분산분석

```python
import scipy.stats as stats

# 데이터
groupA = [85, 92, 78, 88, 83, 90, 76, 84, 92, 87]
groupB = [79, 69, 84, 78, 79, 83, 79, 81, 86, 88]
groupC = [75, 68, 74, 65, 77, 72, 70, 73, 78, 75]

# 일원배치법 수행
f_value, p_value = stats.f_oneway(groupA, groupB, groupC) # 이것도 알아놓자.

# F-value
print(round(f_value,2))

# p-value
print(format(p_value,'.6f'))
```

# 카이제곱검정

- 보통 비율로 나타난 것이 기대도수, 실제 수로 나타낸 것이 관찰도수.
- 순서 너무너무 중요!! chisquare(기대도수, 관찰도수) 순으로 입력해야 함! 왜냐면 분자 분모 식 설정해야해서..

# 지지도, 신뢰도, 향상도.

- 라이브러리 안 쓰고 풀 수 있다. 연습하자.

```python
import pandas as pd

# 데이터
df = pd.DataFrame({
    'transaction': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    '빼빼로': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],
    '딴짓초코': [0, 1, 1, 0, 1, 0, 1, 1, 0, 0],
    '양조위빵': [1, 0, 0, 1, 1, 1, 0, 0, 1, 0],
    '오징어칩': [0, 1, 1, 0, 0, 1, 0, 1, 1, 1],
    '초코파이': [1, 1, 0, 0, 1, 0, 1, 1, 0, 0]
})

```

# 포아송 분포

```python
from scipy.stats import poisson

# 평균 발생 횟수 (하루에 잡지를 구매하는 고객 수)
lambda_ = 3

# 하루에 정확히 5명의 고객이 잡지를 구매할 확률
print(poisson.pmf(5, lambda_))

# 하루에 적어도 2명의 고객이 잡지를 구매할 확률
print(1 - poisson.cdf(1, lambda_))

연습하자!
정확히 n-> poisson.pmf(n, lambda)
적어도 n -> 1-poisson.cdf(n-1, lambda)
```

# 로지스틱 회귀에서 범주형 변수 reference 지정하기

- C(salary_level, Treatment(reference="low"))
  -> salary_level을 Category로 명시하고, Treatment(reference='low')를 통해, salary_level의 'low'값을 기준삼기.

- model=logit('left_company~satisfaction+C(salary_level, Treatment(reference="low"))+project_count+working_hours',data=df).fit()
  - 여기서 왜 reference="low"에 큰따옴표를 붙여야할까?
    - logit() 내 formula를 'formula'로 묶고있기 때문에, 중간에 'low'를 해버리면, low를 기준으로 'formula앞쪽'low'formula뒷쪽' 이 되어버린다. 주의하자.

# 분산의 차이를 알아보는 F검정.

- a.var(), b.var()구한 후, 큰 값을 분자로 해서 varB/varA
- 합동분산추정량
  - (varA*A집단자유도) + (VarB*B집단자유도) / A집단자유도+B집단자유도

# 판다스 기본함수 중 몰랐던 것들 정리.

- mean(), max() 말고도..

1. skew(): 왜도
2. kurt(): 첨도

3. cumsum(): 누적합
4. cumprod(): 누적곱

5. sem(): 평균의 표준오차: s/sqrt(n) (표준편차/루트 표본크기)
6. mad(): 평균 절대편차

```python
import pandas as pd
df=pd.read_csv('delivery_time.csv')
df.주문시간=pd.to_datetime(df.주문시간)
df.실제도착시간=pd.to_datetime(df.실제도착시간)
df.예상도착시간=pd.to_datetime(df.예상도착시간)

df['차이']=(df.실제도착시간-df.주문시간).dt.total_seconds()/60
print(round(df.groupby('앱종류').차이.mean().min())) # 가장 빠르다 -> 가장 시간이 작다......................
```

# 라이브러리, 메소드 좀 몰라도 된다.. 근데 정신은 빼놓지 말자..... 독해력이 중요하다.

# grouby를 써서 참 거짓 bool 컬럼의 비율을 구할 땐 mean()을 고려해보자. 왜냐면 True=1 False=0이기 때문에, 참비율은 mean()으로 구할수있다.

```python
import pandas as pd
df=pd.read_csv('delivery_time.csv')
df.주문시간=pd.to_datetime(df.주문시간)

주문min=df.groupby('user').주문시간.min()
주문max=df.groupby('user').주문시간.max()

간격=(주문max-주문min).dt.days

cond1=간격<1
int(sum(간격>간격[~cond1].mean()))
```

- 시계열 데이터 다루는 것 중.. 시차 구하는 것 꼭 가져가자.
- 못 가져갈 것 같긴 하다.. 컴퓨터 그만 보고싶다.

# fillna(), drop() 등 df에 적용한 것 꼭!!!! df에 다시 대입하기! 아니면 inplace=True를 쓰던가..
